import express from 'express';
import dotenv from 'dotenv';
import { GoogleGenerativeAI } from '@google/generative-ai';

dotenv.config();
const router = express.Router();

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
const AI_RESPONSE_MODEL = 'gemini-2.0-flash'; // Using the latest Flash model
function getRandomFloat(min, max) {
    return Math.random() * (max - min) + min;
}

router.post('/', async (req, res) => {
    let { history, difficulty } = req.body;
    if (!difficulty) difficulty = 'easy';
    if (!history) {
        return res.status(400).json({ error: 'Missing history' });
    }
    console.log(difficulty);
    const model = genAI.getGenerativeModel({ model: AI_RESPONSE_MODEL });

    // Format history for Gemini's chat structure
    const chatMessages = [
        {
            role: 'user', // System instructions are often best integrated into the first user prompt or as a separate system instruction for the model config. For chat, starting with a user message is common.
            parts: [{ text: `You are a moderate debater. Respond clearly, and concisely. Your difficulty level is ${difficulty}.In easy mode, allow the user to win by providing a weak argument. dont do som in hard mode. in medium mode, it should be average level. Give 1 strong rebuttal only. It should be of 2-3 lines.` }]
        }
    ];

    history.forEach(entry => {
        chatMessages.push({ role: 'user', parts: [{ text: entry.user }] });
        if (entry.ai) {
            chatMessages.push({ role: 'model', parts: [{ text: entry.ai }] });
        }
    });
    let temp = getRandomFloat(0.6, 0.9);
    try {
        const chat = model.startChat({
            history: chatMessages,
             generationConfig: { // Corresponds to max_new_tokens
                temperature: temp,
            },
        });

        const result = await chat.sendMessage(`Respond as AI:`); // This acts as the final user prompt to trigger the AI's response

        const reply = result.response.text().trim();
        console.log(`AI Reply: ${reply}`);

        if (reply) {
            res.json({ reply });
        } else {
            res.status(500).json({ error: 'No reply generated by AI.' });
        }
    } catch (err) {
        console.error('AI response generation failed:', err);
        res.status(500).json({ error: 'AI response generation failed', details: err.message || 'Unknown error' });
    }
});

export default router;
